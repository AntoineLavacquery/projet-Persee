{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import rdflib\n",
    "from rdflib import URIRef\n",
    "from rdflib.namespace import RDF\n",
    "import xml.etree.ElementTree as ET\n",
    "import networkx as nx\n",
    "import regex as re\n",
    "import fuzzywuzzy\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/person_review_name.csv', sep='\\s*,\\s*', engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrée : URL / Sortie : return(XML)\n",
    "def rdf_to_xml(url):\n",
    "    try:\n",
    "        g = rdflib.Graph().parse(url)\n",
    "        serial = g.serialize(format='pretty-xml')\n",
    "        root = ET.fromstring(serial)\n",
    "        return(root)\n",
    "    except:\n",
    "        print('Fin du dataframe ?')\n",
    "\n",
    "# Entrée : liste d'URL / Sortie : liste de noms, d'URL en cas d'erreur\n",
    "def url_to_name(cites_urls):\n",
    "    cites_names = []\n",
    "    id_publishs = []\n",
    "    for cite in cites_urls:\n",
    "        url = cite\n",
    "        root = rdf_to_xml(url)\n",
    "        try:\n",
    "            id_publish = (re.findall('(?<=persee.fr\\/doc\\/)[a-z]+(?=_[0-9]+)', url))[0]\n",
    "            id_publishs.append(id_publish)\n",
    "\n",
    "            bib_cit = root.find('.//{http://purl.org/dc/terms/}bibliographicCitation').text\n",
    "            name = (re.findall('^[^.]+', bib_cit))[0]\n",
    "            cites_names.append(name)\n",
    "        except:\n",
    "            cites_names.append(url)\n",
    "            id_publishs.append(id_publish)\n",
    "    return(cites_names, id_publishs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net_meta = nx.Graph()\n",
    "net_meta = nx.DiGraph()\n",
    "\n",
    "nb_a_traiter = len(df.index)\n",
    "\n",
    "for i in range(nb_a_traiter):\n",
    "# for i in range(100):\n",
    "    url_df = df.loc[i]['Review_18']\n",
    "    root = rdf_to_xml(url_df)\n",
    "\n",
    "    bib_cit = root.find('.//{http://purl.org/dc/terms/}bibliographicCitation').text\n",
    "    \n",
    "    name_df = df.loc[i]['name_86']\n",
    "    name_rdf_bib = (re.findall('^[^.]+', bib_cit))[0]\n",
    "\n",
    "    # if fuzz.token_sort_ratio(name_df, name_rdf_bib) >= 90:\n",
    "    #     print(f'{name_df} = {name_rdf_bib}')\n",
    "\n",
    "    cites_url = []\n",
    "    isCitedBy_url = []\n",
    "\n",
    "    for elem in root.iter('{http://purl.org/spar/cito/}cites'):\n",
    "        cite_url = list(elem.attrib.values())[0]\n",
    "        if cite_url not in cites_url:\n",
    "            if cite_url != url_df:\n",
    "                cites_url.append(cite_url)\n",
    "    if cites_url:\n",
    "        cites_names = (url_to_name(cites_url))[0]\n",
    "        id_publishs = (url_to_name(cites_url))[1]\n",
    "\n",
    "    # for elem in root.iter('{http://purl.org/spar/cito/}isCitedBy'):\n",
    "    #     cite_url = list(elem.attrib.values())[0]\n",
    "    #     if cite_url not in isCitedBy_url:\n",
    "    #         if cite_url != url_df:\n",
    "    #             print(f'Ça marche pour {i}')\n",
    "    #             isCitedBy_url.append(cite_url)\n",
    "    # if isCitedBy_url:\n",
    "    #     isCitedBy_names = url_to_name(isCitedBy_url)\n",
    "\n",
    "    if name_rdf_bib not in net_meta:\n",
    "        net_meta.add_node(name_rdf_bib, corpus=True, publishing='jds', nPaper=1) #id=url, bib_cit=bib_cit, nCitation=0)\n",
    "    else:\n",
    "        net_meta.nodes[name_rdf_bib][\"nPaper\"] += 1\n",
    "\n",
    "    for name_or_url, id_publish in zip(cites_names, id_publishs):\n",
    "        if name_or_url not in net_meta:\n",
    "            net_meta.add_node(name_or_url, corpus=False, publishing=id_publish, nPaper=1)\n",
    "        if net_meta.has_edge(name_rdf_bib, name_or_url):\n",
    "            net_meta[name_rdf_bib][name_or_url][\"weight\"] += 1\n",
    "        else:\n",
    "            net_meta.add_edge(name_rdf_bib, name_or_url, weight=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(net_meta))\n",
    "nx.draw(net_meta)\n",
    "nx.write_gexf(net_meta, f'graph_meta_{nb_a_traiter}.gexf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (main, Dec 15 2022, 17:11:09) [Clang 14.0.0 (clang-1400.0.29.202)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
