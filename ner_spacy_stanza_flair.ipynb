{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NER"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fichier pris en entrée :\n",
    "- clean_{date}.json -> provient du notebook **nettoyeur**\n",
    "\n",
    "Fichiers de sortie produits par le notebook :\n",
    "- NLP_{date}_{type_pipeline}_{nombre_resultats}.html -> **fichier HTML des résultats de la NER**\n",
    "\n",
    "- NLP_{date}_{type_pipeline}_{nombre_resultats}.csv -> **tableau avec autant de lignes que de résultats et deux colonnes : titre et pers**\n",
    "**-> pers** = entitées nommées \"personnage\" issues de spacy pour lesquelles un traitement de nettoyage a été effectué :\n",
    "    - suppression des termes inférieur à 2 caractères\n",
    "    - suppression des doublons malgré d'éventuelles coquilles d'OCR dans la graphie du nom -> la graphie retenue est celle qui revient le plus de fois au sein du CR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from collections import Counter\n",
    "import fr_core_news_lg # md, sm\n",
    "nlp = fr_core_news_lg.load()\n",
    "from datetime import date\n",
    "import time\n",
    "import json\n",
    "import itertools\n",
    "import regex as re\n",
    "import fuzzywuzzy\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables à changer par l'utilisateur\n",
    "source_json = 'results/clean_w_names_24-01-23.json'\n",
    "pipeline = \"fr_core_news_lg\" # /!\\ PENSER À CHANGER PLUS HAUT\n",
    "\n",
    "# Importation des données depuis le JSON\n",
    "df = pd.read_json(source_json, orient='index')\n",
    "\n",
    "# Nombre de résultats dans la réponse produite, varie en fonction des essais\n",
    "# nb_a_traiter = len(df.index)\n",
    "nb_a_traiter = 100\n",
    "\n",
    "# Variable permettant de compter puis d'inscrire le nombre de \"personnes\" détéctées par la NER dans le nom du fichier de sortie final (pour contrôle)\n",
    "count_names = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition de l'en tête général\n",
    "date = time.strftime(\"%d-%m-%y\")\n",
    "\n",
    "# (Re)création d'un fichier de sortie propre + en tête\n",
    "nom_fichier = f\"results/NLP_{date}_{pipeline[-2:]}_{nb_a_traiter}r_{count_names}n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lists = []\n",
    "\n",
    "# Boucle de constitution : export PER + HTML\n",
    "for i in range(nb_a_traiter):\n",
    "    # NLP par spacy --------------------------------------------------------------------------\n",
    "    title = df.loc[i, 'area_title']\n",
    "    text = df.loc[i, 'area_text']\n",
    "    extracted_names = df.loc[i, 'extracted_names']\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # Constitution de la grande liste destinée à être convertie en df ------------------------\n",
    "    pers = [(ent.text) for ent in doc.ents if ent.label_ == \"PER\"]\n",
    "    # list = [title, pers, extracted_names]\n",
    "    list = [title, pers, pers]\n",
    "    lists.append(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion de la liste vers df\n",
    "df_PER = pd.DataFrame(lists, columns=['title', 'pers', 'extracted_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction de nettoyage de la liste des entitées reconnues\n",
    "def clean_names(list):\n",
    "    patterns = [\n",
    "        r'^M\\.',\n",
    "        r'^MM\\.',\n",
    "        r'^MMe.',\n",
    "        r'^MMe ',\n",
    "        r'^ +',\n",
    "    ]\n",
    "    for i in range(len(list)):\n",
    "        for pattern in patterns:\n",
    "            list[i] = re.sub(pattern, '', list[i])\n",
    "    return(list)\n",
    "\n",
    "# Comptage des termes au sein de la liste\n",
    "def make_count(list):\n",
    "    list_count = []\n",
    "    for i in range(len(list)):\n",
    "        mot = list[i]\n",
    "        count = list.count(list[i])\n",
    "        list_count.append([mot, count])\n",
    "    return(list_count)\n",
    "\n",
    "# Fonction de comparaisons des mots 2 à 2 : lorsque plusieurs noms sont similaires, on n'en garde qu'un\n",
    "# Fonction qui prend une liste en entrée et ressort une liste en sortie\n",
    "def keep_best_name(list):\n",
    "    discri_list = [\n",
    "        r'^[\\P{Lu}]',\n",
    "        r'[0-9]+',\n",
    "        r'\\.$',\n",
    "        r'\\\"|\\'|\\\\|\\/|«|»'\n",
    "    ]\n",
    "\n",
    "    # Pour chaque mot\n",
    "    temp_list = []\n",
    "    for i in range(len(list)):\n",
    "        ref = list[i]\n",
    "\n",
    "        # On va comparera avec tous autres mots de la liste\n",
    "        for j in range(len(list)):\n",
    "            # Si on confronte le mot avec lui même -> on ne fait rien\n",
    "            if i == j:\n",
    "                pass\n",
    "            else:\n",
    "                # Sinon comparaison du score entre les deux noms\n",
    "                ratio = fuzz.token_sort_ratio(ref[0], list[j][0])\n",
    "                partial_ratio = fuzz.partial_ratio(ref[0], list[j][0])\n",
    "                if ratio > 85 or partial_ratio > 85:\n",
    "                    # Si le second mot est présent plus de fois, on le retient lui\n",
    "                    if ref[1] < list[j][1]:\n",
    "                        ref = list[j]\n",
    "\n",
    "        # Discrimination des noms de 2 lettres ou moins, ceux qui contiennent de chiffres, qui ne commencent pas par une maj et ceux ne contenant pas de voyelles\n",
    "        if (ref[0] not in temp_list) & (len(ref[0]) > 2):\n",
    "            ready = True\n",
    "            for pattern in discri_list:\n",
    "                if re.search(pattern, ref[0]):\n",
    "                    ready = False\n",
    "                if not re.search('(?i)[aeiouy]+', ref[0]):\n",
    "                    ready = False\n",
    "            if ready:\n",
    "                temp_list.append(ref[0])\n",
    "    return(temp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour chaque ligne de notre tableau de départ\n",
    "for i in range(len(df_PER.index)):\n",
    "    # On appelle la fonction de nettoyage sur nos entitées \"personnes\"\n",
    "    list_PER_clean = clean_names(df_PER['pers'][i])\n",
    "    # Chaque entitée est compté, un nombre d'occurence lui est attribué = [['Personne1', 2], ['Personne2', 3], ['Personne3', 1], ['Personne4', 1]]\n",
    "    list_PER_count = make_count(list_PER_clean)\n",
    "    # De tous les noms qui se ressemblent (= coquilles dans la graphie), on ne garde que l'occurence qui est apparue le plus de fois\n",
    "    best_names = keep_best_name(list_PER_count)\n",
    "    # Décompte pour contrôle \n",
    "    count_names += len(best_names)\n",
    "    # Màj de notre liste d'entités \"personnes\" au sein du dataframe\n",
    "    df_PER.at[i, 'pers'] = best_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Re)création d'un fichier de sortie propre + en tête\n",
    "nom_fichier = f\"results/NLP_{date}_{pipeline[-2:]}_{nb_a_traiter}r_{count_names}n\"\n",
    "\n",
    "# Conversion du df vers csv\n",
    "df_PER.to_csv(f\"{nom_fichier}.csv\")\n",
    "\n",
    "count_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "after = df_PER['pers'][0]\n",
    "print(f'AVANT : {before}')\n",
    "print('----------------------')\n",
    "print(f'APRÈS : {after}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (main, Dec 15 2022, 17:11:09) [Clang 14.0.0 (clang-1400.0.29.202)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
